{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f38eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DataPreprocessor imported successfully!\n",
      " DataPreprocessor initialized successfully!\n",
      " Raw data path: ../data/raw\n",
      " Processed data path: ../data/processed\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Test DataPreprocessor Import and Initialization\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.stock_predictor.preprocessing import DataPreprocessor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print(\" DataPreprocessor imported successfully!\")\n",
    "\n",
    "# Initialize preprocessor\n",
    "try:\n",
    "    preprocessor = DataPreprocessor(\"../config/config.yaml\")\n",
    "    print(\" DataPreprocessor initialized successfully!\")\n",
    "    print(f\" Raw data path: {preprocessor.raw_data_path}\")\n",
    "    print(f\" Processed data path: {preprocessor.processed_data_path}\")\n",
    "except Exception as e:\n",
    "    print(f\" Initialization failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecaf504a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 1 raw data files:\n",
      "    RELIANCE_20250814_213917.parquet\n",
      "\n",
      "Test file loaded: 67 rows, 12 columns\n",
      "Columns: ['Datetime', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'Symbol', 'Source', 'Exchange', 'Currency']\n",
      "Date range: 2025-05-14 00:00:00+05:30 to 2025-08-14 00:00:00+05:30\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Check what raw data files are available for processing\n",
    "raw_yahoo_path = Path(\"../data/raw/yahoo_finance\")\n",
    "\n",
    "if raw_yahoo_path.exists():\n",
    "    raw_files = list(raw_yahoo_path.glob(\"*.parquet\"))\n",
    "    print(f\"üîç Found {len(raw_files)} raw data files:\")\n",
    "    for file in raw_files:\n",
    "        print(f\"    {file.name}\")\n",
    "        \n",
    "    if raw_files:\n",
    "        # Test loading a single file\n",
    "        test_file = raw_files[0]\n",
    "        try:\n",
    "            test_df = preprocessor.load_raw_data(test_file)\n",
    "            print(f\"\\nTest file loaded: {len(test_df)} rows, {len(test_df.columns)} columns\")\n",
    "            print(f\"Columns: {list(test_df.columns)}\")\n",
    "            print(f\"Date range: {test_df['Datetime'].min()} to {test_df['Datetime'].max()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading test file: {e}\")\n",
    "    else:\n",
    "        print(\"No raw data files found! Run your data fetching notebook first.\")\n",
    "else:\n",
    "    print(\"Raw data directory doesn't exist! Run your data fetching notebook first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68363bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing technical indicators calculation...\n",
      "Technical indicators added successfully!\n",
      "Original columns: 12\n",
      "After indicators: 34\n",
      "üéØ Key indicators added: ['SMA_20', 'MACD', 'RSI', 'BB_Upper', 'BB_Lower', 'Volatility']\n",
      "\n",
      " Sample Technical Indicators (last 5 rows):\n",
      "                    Datetime    Close     SMA_20        RSI       MACD  \\\n",
      "62 2025-08-08 00:00:00+05:30  1362.36  1415.3275  33.847221 -23.424485   \n",
      "63 2025-08-11 00:00:00+05:30  1380.69  1410.4720  43.030781 -22.870507   \n",
      "64 2025-08-12 00:00:00+05:30  1374.91  1405.2430  38.043242 -22.633825   \n",
      "65 2025-08-13 00:00:00+05:30  1377.10  1400.1135  43.860075 -22.016539   \n",
      "66 2025-08-14 00:00:00+05:30  1373.80  1395.2770  46.058673 -21.543667   \n",
      "\n",
      "    Volatility  \n",
      "62    0.011546  \n",
      "63    0.012178  \n",
      "64    0.012133  \n",
      "65    0.012161  \n",
      "66    0.012147  \n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Test technical indicators calculation on a single stock\n",
    "if 'test_df' in locals() and not test_df.empty:\n",
    "    try:\n",
    "        print(\"Testing technical indicators calculation...\")\n",
    "        \n",
    "        # Test technical indicators\n",
    "        df_with_indicators = preprocessor.calculate_technical_indicators(test_df)\n",
    "        \n",
    "        print(f\"Technical indicators added successfully!\")\n",
    "        print(f\"Original columns: {len(test_df.columns)}\")\n",
    "        print(f\"After indicators: {len(df_with_indicators.columns)}\")\n",
    "        \n",
    "        # Check specific indicators\n",
    "        indicator_columns = [col for col in df_with_indicators.columns if col in \n",
    "                           ['SMA_20', 'RSI', 'MACD', 'BB_Upper', 'BB_Lower', 'Volatility']]\n",
    "        print(f\"üéØ Key indicators added: {indicator_columns}\")\n",
    "        \n",
    "        # Show sample of technical indicators\n",
    "        print(\"\\n Sample Technical Indicators (last 5 rows):\")\n",
    "        sample_cols = ['Datetime', 'Close', 'SMA_20', 'RSI', 'MACD', 'Volatility']\n",
    "        available_cols = [col for col in sample_cols if col in df_with_indicators.columns]\n",
    "        print(df_with_indicators[available_cols].tail())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Technical indicators calculation failed: {e}\")\n",
    "else:\n",
    "    print(\" No test data available for technical indicators test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09e5ec8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing complete ML preprocessing pipeline...\n",
      " ML preprocessing completed for RELIANCE.NS!\n",
      " Final dataset shape: (67, 39)\n",
      "üáÆüá≥ Indian market features: ['Day_of_Week', 'Month', 'Quarter', 'Is_Month_End', 'Is_Quarter_End']\n",
      " Missing values after preprocessing: 0\n",
      "\n",
      " Final ML-ready dataset (last 3 rows):\n",
      "                    Datetime    Close     SMA_20        RSI       MACD  \\\n",
      "64 2025-08-12 00:00:00+05:30  1374.91  1405.2430  38.043242 -22.633825   \n",
      "65 2025-08-13 00:00:00+05:30  1377.10  1400.1135  43.860075 -22.016539   \n",
      "66 2025-08-14 00:00:00+05:30  1373.80  1395.2770  46.058673 -21.543667   \n",
      "\n",
      "    Day_of_Week  Is_Month_End  \n",
      "64            1             0  \n",
      "65            2             0  \n",
      "66            3             0  \n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Test complete ML preprocessing pipeline on single stock\n",
    "if 'test_df' in locals() and not test_df.empty:\n",
    "    try:\n",
    "        print(\" Testing complete ML preprocessing pipeline...\")\n",
    "        \n",
    "        # Get symbol from test data\n",
    "        symbol = test_df['Symbol'].iloc[0] if 'Symbol' in test_df.columns else \"TEST_STOCK\"\n",
    "        \n",
    "        # Run complete preprocessing\n",
    "        processed_df = preprocessor.preprocess_for_ml(test_df, symbol)\n",
    "        \n",
    "        print(f\" ML preprocessing completed for {symbol}!\")\n",
    "        print(f\" Final dataset shape: {processed_df.shape}\")\n",
    "        \n",
    "        # Check for Indian market features\n",
    "        indian_features = [col for col in processed_df.columns if col in \n",
    "                          ['Day_of_Week', 'Month', 'Quarter', 'Is_Month_End', 'Is_Quarter_End']]\n",
    "        print(f\"üáÆüá≥ Indian market features: {indian_features}\")\n",
    "        \n",
    "        # Check data quality\n",
    "        missing_data = processed_df.isnull().sum().sum()\n",
    "        print(f\" Missing values after preprocessing: {missing_data}\")\n",
    "        \n",
    "        # Show sample of final dataset\n",
    "        print(\"\\n Final ML-ready dataset (last 3 rows):\")\n",
    "        display_cols = ['Datetime', 'Close', 'SMA_20', 'RSI', 'MACD', 'Day_of_Week', 'Is_Month_End']\n",
    "        available_display = [col for col in display_cols if col in processed_df.columns]\n",
    "        print(processed_df[available_display].tail(3))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" ML preprocessing failed: {e}\")\n",
    "else:\n",
    "    print(\" No test data available for ML preprocessing test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "406eac6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing LSTM sequence creation...\n",
      " LSTM sequences created successfully!\n",
      " Input sequences shape: (37, 30, 14)\n",
      " Target values shape: (37,)\n",
      " Scaler type: MinMaxScaler\n",
      " Expected features: 14, Actual features: 14\n",
      " Sequence length: 30 time steps\n",
      " Number of sequences: 37\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Test LSTM sequence creation\n",
    "if 'processed_df' in locals() and not processed_df.empty:\n",
    "    try:\n",
    "        print(\" Testing LSTM sequence creation...\")\n",
    "        \n",
    "        # Test with smaller sequence length for testing\n",
    "        X, y, scaler = preprocessor.create_sequences_for_lstm(\n",
    "            processed_df, \n",
    "            sequence_length=30,  # Smaller for testing\n",
    "            prediction_horizon=1\n",
    "        )\n",
    "        \n",
    "        print(f\" LSTM sequences created successfully!\")\n",
    "        print(f\" Input sequences shape: {X.shape}\")\n",
    "        print(f\" Target values shape: {y.shape}\")\n",
    "        print(f\" Scaler type: {type(scaler).__name__}\")\n",
    "        \n",
    "        # Validate sequence dimensions\n",
    "        expected_features = len([col for col in ['Open', 'High', 'Low', 'Close', 'Volume', \n",
    "                                               'SMA_5', 'SMA_10', 'SMA_20', 'RSI', 'MACD',\n",
    "                                               'Price_Change', 'Volatility', 'Volume_Ratio', 'HL_Spread'] \n",
    "                               if col in processed_df.columns])\n",
    "        \n",
    "        print(f\" Expected features: {expected_features}, Actual features: {X.shape[2]}\")\n",
    "        print(f\" Sequence length: {X.shape[1]} time steps\")\n",
    "        print(f\" Number of sequences: {X.shape[0]}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" LSTM sequence creation failed: {e}\")\n",
    "else:\n",
    "    print(\" No processed data available for LSTM sequence test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb072406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing batch processing of all raw data...\n",
      "‚úÖ Batch processing completed!\n",
      "üìÅ Successfully processed 1 files\n",
      "   1. RELIANCE_ml_ready_20250815_114735.parquet\n",
      "\n",
      " Processed files details:\n",
      "    RELIANCE_ml_ready_20250815_114735.parquet: 67 rows √ó 39 cols (35.1 KB)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Test batch processing of all raw data files\n",
    "print(\" Testing batch processing of all raw data...\")\n",
    "\n",
    "try:\n",
    "    # Process all raw data files\n",
    "    processed_files = preprocessor.process_all_raw_data()\n",
    "    \n",
    "    print(f\"‚úÖ Batch processing completed!\")\n",
    "    print(f\"üìÅ Successfully processed {len(processed_files)} files\")\n",
    "    \n",
    "    # Show processed files\n",
    "    for i, file_path in enumerate(processed_files, 1):\n",
    "        print(f\"   {i}. {file_path.name}\")\n",
    "        \n",
    "    # Verify processed files exist and show file sizes\n",
    "    print(f\"\\n Processed files details:\")\n",
    "    for file_path in processed_files:\n",
    "        if file_path.exists():\n",
    "            file_size = file_path.stat().st_size / 1024  # Size in KB\n",
    "            \n",
    "            # Quick load to get shape\n",
    "            df = pd.read_parquet(file_path)\n",
    "            print(f\"    {file_path.name}: {df.shape[0]} rows √ó {df.shape[1]} cols ({file_size:.1f} KB)\")\n",
    "        else:\n",
    "            print(f\"    {file_path.name}: File not found!\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\" Batch processing failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e61a26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PREPROCESSING PIPELINE VALIDATION SUMMARY\n",
      "==================================================\n",
      " Processed data directory: 2 files\n",
      " ML-ready files: 2\n",
      "\n",
      " Sample ML-ready dataset validation (RELIANCE_ml_ready_20250815_001203.parquet):\n",
      "    Shape: (67, 39)\n",
      "    Date range: 2025-05-14 00:00:00+05:30 to 2025-08-14 00:00:00+05:30\n",
      "    Technical indicators: 5/5 present\n",
      "  Indian market features: 4/4 present\n",
      "   üîç Data quality: 0 missing values\n",
      "\n",
      " PREPROCESSING PIPELINE: READY FOR LSTM MODEL TRAINING!\n",
      "\n",
      " Next Step: Ready for Step 4 - LSTM Model Development\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Final validation and summary\n",
    "print(\" PREPROCESSING PIPELINE VALIDATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check processed data directory\n",
    "processed_path = Path(\"../data/processed\")\n",
    "if processed_path.exists():\n",
    "    all_processed = list(processed_path.glob(\"*.parquet\"))\n",
    "    print(f\" Processed data directory: {len(all_processed)} files\")\n",
    "    \n",
    "    # Check file naming convention\n",
    "    ml_ready_files = [f for f in all_processed if \"ml_ready\" in f.name]\n",
    "    print(f\" ML-ready files: {len(ml_ready_files)}\")\n",
    "    \n",
    "    # Sample one file for final validation\n",
    "    if ml_ready_files:\n",
    "        sample_file = ml_ready_files[0]\n",
    "        sample_df = pd.read_parquet(sample_file)\n",
    "        \n",
    "        print(f\"\\n Sample ML-ready dataset validation ({sample_file.name}):\")\n",
    "        print(f\"    Shape: {sample_df.shape}\")\n",
    "        print(f\"    Date range: {sample_df['Datetime'].min()} to {sample_df['Datetime'].max()}\")\n",
    "        \n",
    "        # Check for key technical indicators\n",
    "        key_indicators = ['SMA_20', 'RSI', 'MACD', 'BB_Upper', 'Volatility']\n",
    "        available_indicators = [ind for ind in key_indicators if ind in sample_df.columns]\n",
    "        print(f\"    Technical indicators: {len(available_indicators)}/{len(key_indicators)} present\")\n",
    "        \n",
    "        # Check for Indian market features\n",
    "        indian_features = ['Day_of_Week', 'Month', 'Is_Month_End', 'Is_Quarter_End']\n",
    "        available_indian = [feat for feat in indian_features if feat in sample_df.columns]\n",
    "        print(f\"  Indian market features: {len(available_indian)}/{len(indian_features)} present\")\n",
    "        \n",
    "        # Data quality check\n",
    "        missing_count = sample_df.isnull().sum().sum()\n",
    "        print(f\"   üîç Data quality: {missing_count} missing values\")\n",
    "        \n",
    "        print(f\"\\n PREPROCESSING PIPELINE: READY FOR LSTM MODEL TRAINING!\")\n",
    "        \n",
    "else:\n",
    "    print(\" No processed data directory found!\")\n",
    "\n",
    "print(\"\\n Next Step: Ready for Step 4 - LSTM Model Development\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36324e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
