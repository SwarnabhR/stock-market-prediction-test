{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f38eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DataPreprocessor imported successfully!\n",
      "✅ DataPreprocessor initialized successfully!\n",
      "📁 Raw data path: ../data/raw\n",
      "📁 Processed data path: ../data/processed\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Test DataPreprocessor Import and Initialization\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.stock_predictor.preprocessing import DataPreprocessor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"✅ DataPreprocessor imported successfully!\")\n",
    "\n",
    "# Initialize preprocessor\n",
    "try:\n",
    "    preprocessor = DataPreprocessor(\"../config/config.yaml\")\n",
    "    print(\"✅ DataPreprocessor initialized successfully!\")\n",
    "    print(f\"📁 Raw data path: {preprocessor.raw_data_path}\")\n",
    "    print(f\"📁 Processed data path: {preprocessor.processed_data_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Initialization failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecaf504a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Found 1 raw data files:\n",
      "   📄 RELIANCE_20250814_213917.parquet\n",
      "\n",
      "✅ Test file loaded: 67 rows, 12 columns\n",
      "📊 Columns: ['Datetime', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'Symbol', 'Source', 'Exchange', 'Currency']\n",
      "📅 Date range: 2025-05-14 00:00:00+05:30 to 2025-08-14 00:00:00+05:30\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Check what raw data files are available for processing\n",
    "raw_yahoo_path = Path(\"../data/raw/yahoo_finance\")\n",
    "\n",
    "if raw_yahoo_path.exists():\n",
    "    raw_files = list(raw_yahoo_path.glob(\"*.parquet\"))\n",
    "    print(f\"🔍 Found {len(raw_files)} raw data files:\")\n",
    "    for file in raw_files:\n",
    "        print(f\"   📄 {file.name}\")\n",
    "        \n",
    "    if raw_files:\n",
    "        # Test loading a single file\n",
    "        test_file = raw_files[0]\n",
    "        try:\n",
    "            test_df = preprocessor.load_raw_data(test_file)\n",
    "            print(f\"\\n✅ Test file loaded: {len(test_df)} rows, {len(test_df.columns)} columns\")\n",
    "            print(f\"📊 Columns: {list(test_df.columns)}\")\n",
    "            print(f\"📅 Date range: {test_df['Datetime'].min()} to {test_df['Datetime'].max()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading test file: {e}\")\n",
    "    else:\n",
    "        print(\"❌ No raw data files found! Run your data fetching notebook first.\")\n",
    "else:\n",
    "    print(\"❌ Raw data directory doesn't exist! Run your data fetching notebook first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68363bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Testing technical indicators calculation...\n",
      "✅ Technical indicators added successfully!\n",
      "📊 Original columns: 12\n",
      "📊 After indicators: 34\n",
      "🎯 Key indicators added: ['SMA_20', 'MACD', 'RSI', 'BB_Upper', 'BB_Lower', 'Volatility']\n",
      "\n",
      "📈 Sample Technical Indicators (last 5 rows):\n",
      "                    Datetime    Close     SMA_20        RSI       MACD  \\\n",
      "62 2025-08-08 00:00:00+05:30  1362.36  1415.3275  33.847221 -23.424485   \n",
      "63 2025-08-11 00:00:00+05:30  1380.69  1410.4720  43.030781 -22.870507   \n",
      "64 2025-08-12 00:00:00+05:30  1374.91  1405.2430  38.043242 -22.633825   \n",
      "65 2025-08-13 00:00:00+05:30  1377.10  1400.1135  43.860075 -22.016539   \n",
      "66 2025-08-14 00:00:00+05:30  1373.80  1395.2770  46.058673 -21.543667   \n",
      "\n",
      "    Volatility  \n",
      "62    0.011546  \n",
      "63    0.012178  \n",
      "64    0.012133  \n",
      "65    0.012161  \n",
      "66    0.012147  \n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Test technical indicators calculation on a single stock\n",
    "if 'test_df' in locals() and not test_df.empty:\n",
    "    try:\n",
    "        print(\"🔧 Testing technical indicators calculation...\")\n",
    "        \n",
    "        # Test technical indicators\n",
    "        df_with_indicators = preprocessor.calculate_technical_indicators(test_df)\n",
    "        \n",
    "        print(f\"✅ Technical indicators added successfully!\")\n",
    "        print(f\"📊 Original columns: {len(test_df.columns)}\")\n",
    "        print(f\"📊 After indicators: {len(df_with_indicators.columns)}\")\n",
    "        \n",
    "        # Check specific indicators\n",
    "        indicator_columns = [col for col in df_with_indicators.columns if col in \n",
    "                           ['SMA_20', 'RSI', 'MACD', 'BB_Upper', 'BB_Lower', 'Volatility']]\n",
    "        print(f\"🎯 Key indicators added: {indicator_columns}\")\n",
    "        \n",
    "        # Show sample of technical indicators\n",
    "        print(\"\\n📈 Sample Technical Indicators (last 5 rows):\")\n",
    "        sample_cols = ['Datetime', 'Close', 'SMA_20', 'RSI', 'MACD', 'Volatility']\n",
    "        available_cols = [col for col in sample_cols if col in df_with_indicators.columns]\n",
    "        print(df_with_indicators[available_cols].tail())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Technical indicators calculation failed: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ No test data available for technical indicators test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09e5ec8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Testing complete ML preprocessing pipeline...\n",
      "✅ ML preprocessing completed for RELIANCE.NS!\n",
      "📊 Final dataset shape: (67, 39)\n",
      "🇮🇳 Indian market features: ['Day_of_Week', 'Month', 'Quarter', 'Is_Month_End', 'Is_Quarter_End']\n",
      "🔍 Missing values after preprocessing: 0\n",
      "\n",
      "📋 Final ML-ready dataset (last 3 rows):\n",
      "                    Datetime    Close     SMA_20        RSI       MACD  \\\n",
      "64 2025-08-12 00:00:00+05:30  1374.91  1405.2430  38.043242 -22.633825   \n",
      "65 2025-08-13 00:00:00+05:30  1377.10  1400.1135  43.860075 -22.016539   \n",
      "66 2025-08-14 00:00:00+05:30  1373.80  1395.2770  46.058673 -21.543667   \n",
      "\n",
      "    Day_of_Week  Is_Month_End  \n",
      "64            1             0  \n",
      "65            2             0  \n",
      "66            3             0  \n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Test complete ML preprocessing pipeline on single stock\n",
    "if 'test_df' in locals() and not test_df.empty:\n",
    "    try:\n",
    "        print(\"🚀 Testing complete ML preprocessing pipeline...\")\n",
    "        \n",
    "        # Get symbol from test data\n",
    "        symbol = test_df['Symbol'].iloc[0] if 'Symbol' in test_df.columns else \"TEST_STOCK\"\n",
    "        \n",
    "        # Run complete preprocessing\n",
    "        processed_df = preprocessor.preprocess_for_ml(test_df, symbol)\n",
    "        \n",
    "        print(f\"✅ ML preprocessing completed for {symbol}!\")\n",
    "        print(f\"📊 Final dataset shape: {processed_df.shape}\")\n",
    "        \n",
    "        # Check for Indian market features\n",
    "        indian_features = [col for col in processed_df.columns if col in \n",
    "                          ['Day_of_Week', 'Month', 'Quarter', 'Is_Month_End', 'Is_Quarter_End']]\n",
    "        print(f\"🇮🇳 Indian market features: {indian_features}\")\n",
    "        \n",
    "        # Check data quality\n",
    "        missing_data = processed_df.isnull().sum().sum()\n",
    "        print(f\"🔍 Missing values after preprocessing: {missing_data}\")\n",
    "        \n",
    "        # Show sample of final dataset\n",
    "        print(\"\\n📋 Final ML-ready dataset (last 3 rows):\")\n",
    "        display_cols = ['Datetime', 'Close', 'SMA_20', 'RSI', 'MACD', 'Day_of_Week', 'Is_Month_End']\n",
    "        available_display = [col for col in display_cols if col in processed_df.columns]\n",
    "        print(processed_df[available_display].tail(3))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ ML preprocessing failed: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ No test data available for ML preprocessing test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "406eac6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Testing LSTM sequence creation...\n",
      "✅ LSTM sequences created successfully!\n",
      "📐 Input sequences shape: (37, 30, 14)\n",
      "📐 Target values shape: (37,)\n",
      "🔧 Scaler type: MinMaxScaler\n",
      "🎯 Expected features: 14, Actual features: 14\n",
      "🎯 Sequence length: 30 time steps\n",
      "🎯 Number of sequences: 37\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Test LSTM sequence creation\n",
    "if 'processed_df' in locals() and not processed_df.empty:\n",
    "    try:\n",
    "        print(\"🧠 Testing LSTM sequence creation...\")\n",
    "        \n",
    "        # Test with smaller sequence length for testing\n",
    "        X, y, scaler = preprocessor.create_sequences_for_lstm(\n",
    "            processed_df, \n",
    "            sequence_length=30,  # Smaller for testing\n",
    "            prediction_horizon=1\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ LSTM sequences created successfully!\")\n",
    "        print(f\"📐 Input sequences shape: {X.shape}\")\n",
    "        print(f\"📐 Target values shape: {y.shape}\")\n",
    "        print(f\"🔧 Scaler type: {type(scaler).__name__}\")\n",
    "        \n",
    "        # Validate sequence dimensions\n",
    "        expected_features = len([col for col in ['Open', 'High', 'Low', 'Close', 'Volume', \n",
    "                                               'SMA_5', 'SMA_10', 'SMA_20', 'RSI', 'MACD',\n",
    "                                               'Price_Change', 'Volatility', 'Volume_Ratio', 'HL_Spread'] \n",
    "                               if col in processed_df.columns])\n",
    "        \n",
    "        print(f\"🎯 Expected features: {expected_features}, Actual features: {X.shape[2]}\")\n",
    "        print(f\"🎯 Sequence length: {X.shape[1]} time steps\")\n",
    "        print(f\"🎯 Number of sequences: {X.shape[0]}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ LSTM sequence creation failed: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ No processed data available for LSTM sequence test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb072406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏭 Testing batch processing of all raw data...\n",
      "✅ Batch processing completed!\n",
      "📁 Successfully processed 1 files\n",
      "   1. RELIANCE_ml_ready_20250815_001203.parquet\n",
      "\n",
      "📊 Processed files details:\n",
      "   📄 RELIANCE_ml_ready_20250815_001203.parquet: 67 rows × 39 cols (35.1 KB)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Test batch processing of all raw data files\n",
    "print(\"🏭 Testing batch processing of all raw data...\")\n",
    "\n",
    "try:\n",
    "    # Process all raw data files\n",
    "    processed_files = preprocessor.process_all_raw_data()\n",
    "    \n",
    "    print(f\"✅ Batch processing completed!\")\n",
    "    print(f\"📁 Successfully processed {len(processed_files)} files\")\n",
    "    \n",
    "    # Show processed files\n",
    "    for i, file_path in enumerate(processed_files, 1):\n",
    "        print(f\"   {i}. {file_path.name}\")\n",
    "        \n",
    "    # Verify processed files exist and show file sizes\n",
    "    print(f\"\\n📊 Processed files details:\")\n",
    "    for file_path in processed_files:\n",
    "        if file_path.exists():\n",
    "            file_size = file_path.stat().st_size / 1024  # Size in KB\n",
    "            \n",
    "            # Quick load to get shape\n",
    "            df = pd.read_parquet(file_path)\n",
    "            print(f\"   📄 {file_path.name}: {df.shape[0]} rows × {df.shape[1]} cols ({file_size:.1f} KB)\")\n",
    "        else:\n",
    "            print(f\"   ❌ {file_path.name}: File not found!\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"❌ Batch processing failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e61a26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 PREPROCESSING PIPELINE VALIDATION SUMMARY\n",
      "==================================================\n",
      "✅ Processed data directory: 1 files\n",
      "✅ ML-ready files: 1\n",
      "\n",
      "📋 Sample ML-ready dataset validation (RELIANCE_ml_ready_20250815_001203.parquet):\n",
      "   📊 Shape: (67, 39)\n",
      "   📅 Date range: 2025-05-14 00:00:00+05:30 to 2025-08-14 00:00:00+05:30\n",
      "   🎯 Technical indicators: 5/5 present\n",
      "   🇮🇳 Indian market features: 4/4 present\n",
      "   🔍 Data quality: 0 missing values\n",
      "\n",
      "✅ PREPROCESSING PIPELINE: READY FOR LSTM MODEL TRAINING!\n",
      "\n",
      "🚀 Next Step: Ready for Step 4 - LSTM Model Development\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Final validation and summary\n",
    "print(\"🎯 PREPROCESSING PIPELINE VALIDATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check processed data directory\n",
    "processed_path = Path(\"../data/processed\")\n",
    "if processed_path.exists():\n",
    "    all_processed = list(processed_path.glob(\"*.parquet\"))\n",
    "    print(f\"✅ Processed data directory: {len(all_processed)} files\")\n",
    "    \n",
    "    # Check file naming convention\n",
    "    ml_ready_files = [f for f in all_processed if \"ml_ready\" in f.name]\n",
    "    print(f\"✅ ML-ready files: {len(ml_ready_files)}\")\n",
    "    \n",
    "    # Sample one file for final validation\n",
    "    if ml_ready_files:\n",
    "        sample_file = ml_ready_files[0]\n",
    "        sample_df = pd.read_parquet(sample_file)\n",
    "        \n",
    "        print(f\"\\n📋 Sample ML-ready dataset validation ({sample_file.name}):\")\n",
    "        print(f\"   📊 Shape: {sample_df.shape}\")\n",
    "        print(f\"   📅 Date range: {sample_df['Datetime'].min()} to {sample_df['Datetime'].max()}\")\n",
    "        \n",
    "        # Check for key technical indicators\n",
    "        key_indicators = ['SMA_20', 'RSI', 'MACD', 'BB_Upper', 'Volatility']\n",
    "        available_indicators = [ind for ind in key_indicators if ind in sample_df.columns]\n",
    "        print(f\"   🎯 Technical indicators: {len(available_indicators)}/{len(key_indicators)} present\")\n",
    "        \n",
    "        # Check for Indian market features\n",
    "        indian_features = ['Day_of_Week', 'Month', 'Is_Month_End', 'Is_Quarter_End']\n",
    "        available_indian = [feat for feat in indian_features if feat in sample_df.columns]\n",
    "        print(f\"   🇮🇳 Indian market features: {len(available_indian)}/{len(indian_features)} present\")\n",
    "        \n",
    "        # Data quality check\n",
    "        missing_count = sample_df.isnull().sum().sum()\n",
    "        print(f\"   🔍 Data quality: {missing_count} missing values\")\n",
    "        \n",
    "        print(f\"\\n✅ PREPROCESSING PIPELINE: READY FOR LSTM MODEL TRAINING!\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ No processed data directory found!\")\n",
    "\n",
    "print(\"\\n🚀 Next Step: Ready for Step 4 - LSTM Model Development\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36324e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
